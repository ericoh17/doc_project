---
title: "DOC CAR model"
author: "Eric Oh"
date: "8/26/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
suppressMessages(suppressWarnings(library(spdep)))
suppressMessages(suppressWarnings(library(rgdal)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(gdata)))
suppressMessages(suppressWarnings(library(readxl)))
suppressMessages(suppressWarnings(library(dplyr)))

options(scipen = 999)
```

We noticed in [doc_data_overview.md](https://github.com/ericoh17/doc_project/blob/master/doc_data_overview.md) that there was evidence of spatial correlation in number of releases between neighboring zip codes through Philadelphia. Accounting for this spatial correlation is the focus of the current modeling work. 

One of the standard statistics used to assess the strength of this spatial correlation is Moran's $I$, which is defined as

$$
I = \frac{n}{\sum_i \sum_j w_{ij}}\frac{\sum_i \sum_j w_{ij}(X_i-\bar{X})(X_j-\bar{X})}{\sum_i (X_i-\bar{X})^2}
$$
where $$w_{ij}$$ is 1 if zip codes i and j share a border and 0 otherwise. 

```{r, echo = FALSE, comment = NA, message = FALSE}
philly_zip_shape <- readOGR("~/Dropbox/doc_project/Zipcodes_Poly",
                            "Zipcodes_Poly",
                            stringsAsFactors = FALSE)

# require connected edge to be
# considered a neighborhood (queen = F)
philly_nb <- poly2nb(philly_zip_shape,
                     queen = FALSE,
                     row.names = philly_zip_shape$CODE)

philly_nb_listw <- nb2listw(philly_nb, style = "B",
                            zero.policy = TRUE)

doc_dat <- read.csv("~/Dropbox/doc_project/data/johnson_doc_data/PhilaLegalZip-Table 1.csv")

# get total number of releases in each zip code
num_offense_zip <- doc_dat %>%
  group_by(legal_zip_code) %>%
  summarise(count = n()) %>%
  as.data.frame()

num_offense_zip <- num_offense_zip[num_offense_zip$legal_zip_code %in% philly_zip_shape$CODE,]
num_offense_zip$legal_zip_code <- reorder.factor(num_offense_zip$legal_zip_code,
                                                 new.order = c(philly_zip_shape$CODE))

num_offense_zip <- arrange(num_offense_zip, legal_zip_code)

# test for spatial autocorrelation
num_offense_moran_i <- moran.test(num_offense_zip$count,
                                  philly_nb_listw)

print(num_offense_moran_i)

```

We can use Moran's I to perform testing for spatial correlation under the null hypothesis that there is no spatial correlation. Calculating Moran's I on the total number of releases in each zip code from 2007 - 2016 yields a statistic of $0.3878$, compared to a null mean of $-0.0213$ and standard error of $0.0075$, suggesting a high amount of spatial correlation in the number of releases between zip codes. 

# Counts of incarcerated person releases

As seen in [doc_data_overview.md](https://github.com/ericoh17/doc_project/blob/master/doc_data_overview.md) the number of releases across Philadelphia zip codes seems to be quite skewed due to some zip codes having a higher number of releases relative to others. One classical method to handle such skewed data is to take a log transformation of the count of releases. However, there are a number of zip codes in some years with zero releases, meaning we must consider a different transformation that is defined at zero. Thus, we decided to use the inverse hyperbolic sine transformation

$$
\tilde{y}_{it} = \log\left(y_{it} + \sqrt{y_{it}^2 + 1}\right) - \log(2)
$$

where $y_{it}$ is the number of releases in zip code $i$ at time $t$ and $\log(2)$ is subtracted to center the transformed values. The inverse hyperbolic sine transformation has the additional benefit that it can be interpreted the same way as a standard log transformation. Specifically, changes in the transformed number of releases can be interpreted as percent changes in the raw number of releases. 

```{r, echo = FALSE}
# load in data with covariates from census
load("~/Dropbox/doc_project/cleaned_data/release_by_zip_year_cov.RData")

#inverse hyperbolic sine transformation
release_by_zip_year_cov <- release_by_zip_year_cov %>%
  dplyr::mutate(count_tf = log(count + sqrt(count^2 + 1)) - log(2))

```


# Zip code level predictors

We want our model to account for zip code level predictors that might be predictive of the number of releases. To do so, we merge the DOC data with the Census Bureau's American Community Survey, containing information about poverty and income levels for Census tract groups. We utilize [crosswalk files](https://www.huduser.gov/portal/datasets/usps_crosswalk.html) from the U.S. Department of Housing and Urban Development's Office of Policy Development and Research to relate Philadelphia zip codes to Census tract groups. 

From the American Community Survey (ACS), we obtain information about the proportion of households in various states of poverty. Specifically, the ACS has data on the proportion of the population in seven different brackets of income-to-poverty line ratios: [0, 0.5), [0.5, 1), [1, 1.25), [1.25, 1.5), [1.5, 1.85), [1.85, 2), and [2+). For example, the [0.5, 1) bracket represents families with income between $50\%$ of the poverty line and the poverty line, where the poverty line is determined by the Census Bureau according to the size and number of children of a household. 

From this poverty data, we create a single measure of poverty for each zip code by calculating a weighted sum of the proportion of households in each of the seven poverty brackets:

$$
\text{poverty}_{i} = \sum_{j=1}^7 w_j q_{i,j}
$$
$q_{i,j}$ is the proportion of households in zip code $i$ that are in poverty bracket $j$ and $w_j$ is the weight given to poverty bracket $j$. We use decreasing weights w = [1, 5/6, 4/6, 3/6, 2/6, 1/6, 0] to give higher poverty brackets more weight. Thus, the poverty measure ranges from 0 to 1, with higher values indicating a higher level of poverty. 

For more detail on how all of the above was done, see [link_doc_census.R](https://github.com/ericoh17/doc_project/blob/master/link_doc_census.R). 

# CAR priors to account for spatial correlation

Conditional autoregressive (CAR) models are commonly used as prior distributions for spatially correlated random effects with areal spatial data. Let $\Gamma=(\gamma_1,\ldots,\gamma_n)'$ be a vector of random elements for n areal locations that are spatially correlated. The CAR model can then be represented using conditional distributions:

$$
\gamma_i | \gamma_j, j \neq i  \sim \text{N}\left(\rho\sum_{j=1}^n w_{ij}\gamma_j, \tau_i^{-1}\right)
$$
where $w_{ij}$ are weights equal to 1 if zip codes $i$ and $j$ share a border and 0 otherwise and $\tau_i$ is a spatially varying precision parameter. 

It can be proved using Brook's Lemma that the joint distribution of $\Gamma$ is given by

$$
\Gamma \sim \text{N}\left(0, [D_{\tau}(I-\rho B)]^{-1}\right)
$$
where:
* $D_{\tau} = \tau D$
* $D = diag(m_i)$: an $n \times n$ diagonal matrix with $m_i=$ the number of neighbors for zip code $i$
* $I$: an $n \times n$ identity matrix
* $\rho$: parameter controlling spatial dependence ($\rho=0$ implies spatial independence and $\rho=1$ results in an intrinsic conditional autoregressive model)
* $B=D^{-1}W$, the scaled adajency matrix
* $W$: the adajency matrix ($w_{ii}=0, $W_{ij}=1$ if neighbor; 0 otherwise)

We can then write the CAR prior as:

$$
\Gamma \sim \text{N}(0, [\tau(D-\rho W)]^{-1})
$$

# Full Bayesian model

We model the transformed number of releases as follows:

#$$
#y_i \sim \text{Poisson}(\exp\{X_i \gamma + \beta \cdot t + \phi_i + \log(\text{offset}_i\})
#$$

$$
\tilde{y}_{it} = \psi_i + \phi_i t + x_i'\beta + \epsilon_{it}
$$

where $x_i'$ is a design vector of predictor variables for zip code $i$, $\beta$ is the vector of coefficients for those predictor variables, $t$ represents time, $\psi_i$ and $\phi_i$ are zip code specific intercepts and slopes, and $\epsilon_{it} \sim \text{N}(0, \sigma^2_{\epsilon})$. Since we do not expect every zip code to have unique coefficients, we impose CAR priors for $\psi_i$ and $\phi_i$, resulting in

$$
\begin{align*}
\mathbf{\psi} &\sim \text{N}(\psi_0 \cdot \mathbf{1}, \tau^2_{\psi} \cdot \mathbf{\Sigma}^{-1}) \\
\mathbf{\phi} &\sim \text{N}(\phi_0 \cdot \mathbf{1}, \tau^2_{\phi} \cdot \mathbf{\Sigma}^{-1}) 
\end{align*}
$$
where $\mathbf{\Sigma}=\tau(D-\rho W)$. The posterior distribution can then be written as follows:

$$
\begin{align*}
p(\beta, \psi, \phi, \psi_0, \phi_0, \rho, \tau | y) &\propto p(y|\beta, \psi, \phi, \psi_0, \phi_0, \rho, \tau)p(\psi|\psi_0,\tau^2_{\psi},\rho)p(\phi|\phi_0,\tau^2_{\phi},\rho) \\
& \times p(\psi_0)p(\phi_0)p(\tau^2_{\psi})p(\tau^2_{\phi})p(\rho)p(\beta)
\end{align*}
$$

We specify the following prior distributions:

$$
\begin{align*}
\mathbf{\psi} &\sim \text{N}(\psi_0 \cdot \mathbf{1}, \tau^2_{\psi} \cdot \mathbf{\Sigma}^{-1}) \\
\mathbf{\phi} &\sim \text{N}(\phi_0 \cdot \mathbf{1}, \tau^2_{\phi} \cdot \mathbf{\Sigma}^{-1}) \\
p(\psi_0) &\propto 1 \\
p(\phi_0) &\propto 1 \\
p(\tau^2_{\psi}) &\sim \text{Inv-Gamma}(l_{\psi}, k_{\psi}) \\
p(\tau^2_{\phi}) &\sim \text{Inv-Gamma}(l_{\phi}, k_{\phi}) \\
p(\rho) &\sim \text{Uniform}(0,1) \\
p(\mathbf{\beta}) &\sim \text{N}(0, \tau^2_{\beta} \cdot \mathbf{I}) \\
p(\tau^2_{\beta}) &\sim \text{Inv-Gamma}(l_{\beta},k_{\beta}) \\
p(\sigma^2_{\epsilon}) &\sim \text{Inv-Gamma}(l_{\epsilon}, k_{\epsilon})
\end{align*}
$$

# Implementation in Stan

First, we can load the necessary packages and set the MCMC options. 

```{r}
library(ggmcmc)
library(dplyr)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

Next, we setup the necessary data. 

```{r}
# remove 19112 zip code because not in census data
tmp_philly_zip <- philly_zip_shape[!(philly_zip_shape$CODE %in% "19112"),]

tmp_philly_nb <- poly2nb(tmp_philly_zip,
                         queen = FALSE,
                         row.names = tmp_philly_zip$CODE)
philly_nb_mat <- nb2mat(tmp_philly_nb, style = "B",
                        zero.policy = TRUE)

# order dataframe by zip codes and years within zip codes
# also add in numeric time variable
release_by_zip_year_cov <- release_by_zip_year_cov %>%
  dplyr::group_by(legal_zip_code) %>%
  dplyr::arrange(ReleaseYear, .by_group = TRUE) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(time = rep(seq(1, 10), 48))

# remove 19112 from outcome and covariate mat
release_by_zip_year_cov <- release_by_zip_year_cov[!(release_by_zip_year_cov$legal_zip_code %in% 19112),]
design_mat <- as.matrix(release_by_zip_year_cov[,c("poverty_measure",
                                                   "income_measure")])
scaled_design_mat <- scale(design_mat)
X <- model.matrix(~scaled_design_mat)
  
full_dat <- list(n = nrow(X),         # number of observations
                 p = ncol(X),         # number of coefficients
                 l = nrow(philly_nb_mat),  # number of zip codes
                 X = X,               # design matrix
                 y = c(release_by_zip_year_cov$count_tf),  # observed number of cases
                 W = philly_nb_mat)               # adjacency matrix

```

Then, we can fit the model using `rstan`. 

```{r, eval = FALSE}
car_mod <- stan('stan/doc_car.stan', data = full_dat, 
                iter = niter, chains = nchains, verbose = FALSE)
```


